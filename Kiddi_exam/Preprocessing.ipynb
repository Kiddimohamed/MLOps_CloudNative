{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a100fa55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:05:06.128218179Z",
     "start_time": "2023-12-03T12:05:05.254488989Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b2a4ec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:05:14.028245353Z",
     "start_time": "2023-12-03T12:05:11.992811100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./venv/lib/python3.10/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: click in ./venv/lib/python3.10/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.10/site-packages (from nltk) (1.3.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.10/site-packages (from nltk) (2023.10.3)\r\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (from nltk) (4.66.1)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kiddi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a735746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:05:15.697440581Z",
     "start_time": "2023-12-03T12:05:15.675510374Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/kiddi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d649350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:05:16.701331739Z",
     "start_time": "2023-12-03T12:05:16.018684764Z"
    }
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Data/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae86c93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:05:16.717051335Z",
     "start_time": "2023-12-03T12:05:16.707661365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method NDFrame.head of                                                   review sentiment\n0      One of the other reviewers has mentioned that ...  positive\n1      A wonderful little production. <br /><br />The...  positive\n2      I thought this was a wonderful way to spend ti...  positive\n3      Basically there's a family where a little boy ...  negative\n4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n...                                                  ...       ...\n49995  I thought this movie did a down right good job...  positive\n49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n49997  I am a Catholic taught in parochial elementary...  negative\n49998  I'm going to have to disagree with the previou...  negative\n49999  No one expects the Star Trek movies to be high...  negative\n\n[50000 rows x 2 columns]>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04f7c42c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:05:17.238387142Z",
     "start_time": "2023-12-03T12:05:17.220115132Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f705b27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:05:17.812923298Z",
     "start_time": "2023-12-03T12:05:17.806197668Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95481041",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:05:18.039828800Z",
     "start_time": "2023-12-03T12:05:18.029526633Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b227974d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:05:18.235361878Z",
     "start_time": "2023-12-03T12:05:18.226007006Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c51a307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:05:18.412363025Z",
     "start_time": "2023-12-03T12:05:18.369074155Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9629d423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:05:18.597921673Z",
     "start_time": "2023-12-03T12:05:18.527037917Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing_data(text):\n",
    "    text =re.sub(r'<.*?>', '', text)\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    # Join the words back into one string\n",
    "    text = ' '.join(tokens)\n",
    "    \n",
    "    return text\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "450353c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:07:07.287878910Z",
     "start_time": "2023-12-03T12:05:19.071436370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                              review sentiment  \\\n0  One of the other reviewers has mentioned that ...  positive   \n1  A wonderful little production. <br /><br />The...  positive   \n2  I thought this was a wonderful way to spend ti...  positive   \n3  Basically there's a family where a little boy ...  negative   \n4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n\n                                      cleaned_review  \n0  one review mention watch 1 oz episod youll hoo...  \n1  wonder littl product film techniqu unassum old...  \n2  thought wonder way spend time hot summer weeke...  \n3  basic there famili littl boy jake think there ...  \n4  petter mattei love time money visual stun film...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>cleaned_review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>one review mention watch 1 oz episod youll hoo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>wonder littl product film techniqu unassum old...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>thought wonder way spend time hot summer weeke...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>basic there famili littl boy jake think there ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>petter mattei love time money visual stun film...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the cleaning function to the review column\n",
    "data['cleaned_review'] = data['review'].apply(preprocessing_data)\n",
    "\n",
    "# Display the first few rows of the cleaned dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d9b5b1",
   "metadata": {},
   "source": [
    "## ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import mlflow\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T12:21:21.325262088Z",
     "start_time": "2023-12-03T12:21:21.038127606Z"
    }
   },
   "id": "7dd5665f1b9d55fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_review'], data['sentiment'], test_size=0.2, random_state=42)\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfe826eb010aead0"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "['Models/fitted_vectorizer.pkl']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(vectorizer, 'Models/fitted_vectorizer.pkl')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8ba9bd3cefab863"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T12:18:24.462507974Z",
     "start_time": "2023-12-03T12:18:24.427016844Z"
    }
   },
   "id": "aeb1ae329df11973"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "models={\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision tree\": DecisionTreeClassifier()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T12:18:27.863004047Z",
     "start_time": "2023-12-03T12:18:27.859257781Z"
    }
   },
   "id": "618273850d9b10bc"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T12:32:56.475294283Z",
     "start_time": "2023-12-03T12:32:56.426894721Z"
    }
   },
   "id": "b8f50d325ecf5615"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiddi/PycharmProjects/Kiddi_exam/venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/kiddi/PycharmProjects/Kiddi_exam/venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression, Accuracy: 0.885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiddi/PycharmProjects/Kiddi_exam/venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/kiddi/PycharmProjects/Kiddi_exam/venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Naive Bayes, Accuracy: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiddi/PycharmProjects/Kiddi_exam/venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/kiddi/PycharmProjects/Kiddi_exam/venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest, Accuracy: 0.8484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiddi/PycharmProjects/Kiddi_exam/venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/kiddi/PycharmProjects/Kiddi_exam/venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVM, Accuracy: 0.8911\n",
      "Model: Dicision tree, Accuracy: 0.7164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiddi/PycharmProjects/Kiddi_exam/venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/kiddi/PycharmProjects/Kiddi_exam/venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# Function to train and log model\n",
    "def train_and_log_model(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        # Log model and params\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_metrics({\"accuracy\": report['accuracy']})\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        return report['accuracy']\n",
    "\n",
    "# Train and log each model\n",
    "for name, model in models.items():\n",
    "    accuracy = train_and_log_model(name, model, X_train_vec, X_test_vec, y_train, y_test)\n",
    "    print(f\"Model: {name}, Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T13:02:21.779542927Z",
     "start_time": "2023-12-03T12:32:58.018863942Z"
    }
   },
   "id": "8821e0395e76f0cb"
  },
  {
   "cell_type": "markdown",
   "id": "0a5428fa",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71b8c95f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:09:53.930041880Z",
     "start_time": "2023-12-03T12:09:53.525419041Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec589f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:10:03.234391785Z",
     "start_time": "2023-12-03T12:09:59.977280009Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40e6d0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.88      4961\n",
      "    positive       0.87      0.90      0.89      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "predictions = lr_model.predict(X_test_vec)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075d2dd2",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f2114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a long of timee \n",
    "\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_vec, y_train)\n",
    "predictions = svm_model.predict(X_test_vec)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a405c3",
   "metadata": {},
   "source": [
    " ### Random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e363f958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85      4961\n",
      "    positive       0.86      0.84      0.85      5039\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(X_train_vec, y_train)\n",
    "rf_predictions = rf_model.predict(X_test_vec)\n",
    "print(classification_report(y_test, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3138f7c5",
   "metadata": {},
   "source": [
    "### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c8b5e3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nb_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_10896/1386418608.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mnb_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train_vec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mwwnb_predictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnb_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test_vec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclassification_report\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnb_predictions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'nb_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vec, y_train)\n",
    "wwnb_predictions = nb_model.predict(X_test_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e352ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.85      4961\n",
      "    positive       0.85      0.86      0.85      5039\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, wwnb_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0fe134",
   "metadata": {},
   "source": [
    "### Desicion tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d088ead5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.71      0.71      4961\n",
      "    positive       0.71      0.71      0.71      5039\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.71     10000\n",
      "weighted avg       0.71      0.71      0.71     10000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_vec, y_train)\n",
    "dt_predictions = dt_model.predict(X_test_vec)\n",
    "print(classification_report(y_test, dt_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "903c4627",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T14:32:19.807117975Z",
     "start_time": "2023-12-03T14:30:07.611844256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx\r\n",
      "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\r\n",
      "Collecting skl2onnx\r\n",
      "  Downloading skl2onnx-1.15.0-py2.py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from onnx) (1.26.2)\r\n",
      "Requirement already satisfied: protobuf>=3.20.2 in ./venv/lib/python3.10/site-packages (from onnx) (4.25.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.19 in ./venv/lib/python3.10/site-packages (from skl2onnx) (1.3.2)\r\n",
      "Collecting onnxconverter-common>=1.7.0 (from skl2onnx)\r\n",
      "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from onnxconverter-common>=1.7.0->skl2onnx) (23.2)\r\n",
      "Collecting protobuf>=3.20.2 (from onnx)\r\n",
      "  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m152.3 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: scipy>=1.5.0 in ./venv/lib/python3.10/site-packages (from scikit-learn>=0.19->skl2onnx) (1.11.4)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./venv/lib/python3.10/site-packages (from scikit-learn>=0.19->skl2onnx) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.10/site-packages (from scikit-learn>=0.19->skl2onnx) (3.2.0)\r\n",
      "Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m15.7/15.7 MB\u001B[0m \u001B[31m136.2 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:03\u001B[0m\r\n",
      "\u001B[?25hDownloading skl2onnx-1.15.0-py2.py3-none-any.whl (294 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m294.7/294.7 kB\u001B[0m \u001B[31m116.3 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m84.5/84.5 kB\u001B[0m \u001B[31m228.7 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: protobuf, onnx, onnxconverter-common, skl2onnx\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 4.25.1\r\n",
      "    Uninstalling protobuf-4.25.1:\r\n",
      "      Successfully uninstalled protobuf-4.25.1\r\n",
      "Successfully installed onnx-1.15.0 onnxconverter-common-1.14.0 protobuf-3.20.2 skl2onnx-1.15.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx skl2onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75c6bc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: skl2onnx in /home/kiddi/.local/lib/python3.10/site-packages (1.15.0)\n",
      "Requirement already satisfied: onnx in /home/kiddi/.local/lib/python3.10/site-packages (1.15.0)\n",
      "Requirement already satisfied: protobuf in /home/kiddi/.local/lib/python3.10/site-packages (3.20.2)\n",
      "Collecting protobuf\n",
      "  Using cached protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Requirement already satisfied: onnxconverter-common>=1.7.0 in /home/kiddi/.local/lib/python3.10/site-packages (from skl2onnx) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19 in /home/kiddi/.local/lib/python3.10/site-packages (from skl2onnx) (1.3.2)\n",
      "Requirement already satisfied: numpy in /home/kiddi/.local/lib/python3.10/site-packages (from onnx) (1.23.5)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from onnxconverter-common>=1.7.0->skl2onnx) (21.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/lib/python3/dist-packages (from scikit-learn>=0.19->skl2onnx) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/kiddi/.local/lib/python3.10/site-packages (from scikit-learn>=0.19->skl2onnx) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/kiddi/.local/lib/python3.10/site-packages (from scikit-learn>=0.19->skl2onnx) (1.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade skl2onnx onnx protobuf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c57479f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as ONNX: rf_model.onnx\n"
     ]
    }
   ],
   "source": [
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "initial_type = [('float_input', FloatTensorType([None, X_train.shape[0]]))]\n",
    "\n",
    "onnx_model = convert_sklearn(rf_model, initial_types=initial_type)\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "onnx_file_path = \"rf_model.onnx\"\n",
    "with open(onnx_file_path, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(\"Model saved as ONNX:\", onnx_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9cd2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e311a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('preprocessing.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c58a9e",
   "metadata": {},
   "source": [
    "### Fast API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4709e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m92.9/92.9 KB\u001B[0m \u001B[31m752.5 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mm eta \u001B[36m0:00:01\u001B[0m0:01\u001B[0m\n",
      "\u001B[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4\n",
      "  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m381.9/381.9 KB\u001B[0m \u001B[31m1.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m:01\u001B[0m\n",
      "\u001B[?25hCollecting starlette<0.28.0,>=0.27.0\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.0/67.0 KB\u001B[0m \u001B[31m1.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting anyio<4.0.0,>=3.7.1\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m80.9/80.9 KB\u001B[0m \u001B[31m4.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /home/kiddi/.local/lib/python3.10/site-packages (from fastapi) (4.8.0)\n",
      "Collecting exceptiongroup\n",
      "  Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.3)\n",
      "Collecting sniffio>=1.1\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting pydantic-core==2.14.5\n",
      "  Downloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mm eta \u001B[36m0:00:01\u001B[0m[36m0:00:01\u001B[0m\n",
      "\u001B[?25hCollecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: sniffio, pydantic-core, exceptiongroup, annotated-types, pydantic, anyio, starlette, fastapi\n",
      "Successfully installed annotated-types-0.6.0 anyio-3.7.1 exceptiongroup-1.2.0 fastapi-0.104.1 pydantic-2.5.2 pydantic-core-2.14.5 sniffio-1.3.0 starlette-0.27.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3d4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f161b381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
